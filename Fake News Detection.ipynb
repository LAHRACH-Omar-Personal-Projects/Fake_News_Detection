{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inspiration\nCan we use this data set to make an algorithm able to determine if an article is fake news or not ?","metadata":{}},{"cell_type":"markdown","source":"# Workflows","metadata":{}},{"cell_type":"markdown","source":"Obtaining Data > Feature engineering > Scrubbing Data > Exploring Data Analysis > NLP > Models Training > Models Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Step 1 : Make necessary imports","metadata":{}},{"cell_type":"code","source":"# Fundamental pre-processing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# NLP processing\nimport re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:19.843238Z","iopub.execute_input":"2021-10-28T15:44:19.843656Z","iopub.status.idle":"2021-10-28T15:44:21.623261Z","shell.execute_reply.started":"2021-10-28T15:44:19.843555Z","shell.execute_reply":"2021-10-28T15:44:21.622307Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:21.625351Z","iopub.execute_input":"2021-10-28T15:44:21.625674Z","iopub.status.idle":"2021-10-28T15:44:21.822949Z","shell.execute_reply.started":"2021-10-28T15:44:21.625632Z","shell.execute_reply":"2021-10-28T15:44:21.821771Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Step 2 : Obtaining Data","metadata":{}},{"cell_type":"code","source":"# Extracting data into dataframes\nreal_news = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')\nfake_news = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:21.824676Z","iopub.execute_input":"2021-10-28T15:44:21.824970Z","iopub.status.idle":"2021-10-28T15:44:25.319171Z","shell.execute_reply.started":"2021-10-28T15:44:21.824935Z","shell.execute_reply":"2021-10-28T15:44:25.318123Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Accessing few sample records\nreal_news.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.320879Z","iopub.execute_input":"2021-10-28T15:44:25.321196Z","iopub.status.idle":"2021-10-28T15:44:25.343807Z","shell.execute_reply.started":"2021-10-28T15:44:25.321153Z","shell.execute_reply":"2021-10-28T15:44:25.342779Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"fake_news.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.347024Z","iopub.execute_input":"2021-10-28T15:44:25.347399Z","iopub.status.idle":"2021-10-28T15:44:25.360373Z","shell.execute_reply.started":"2021-10-28T15:44:25.347354Z","shell.execute_reply":"2021-10-28T15:44:25.359510Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Step 3 : Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Adding a new column \"isFake\" to identify Real/Fake new articles\nreal_news['isReal'] = 1   # Denote real news as 1\nfake_news['isReal'] = 0   # Denote fake news as 0","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.361970Z","iopub.execute_input":"2021-10-28T15:44:25.363042Z","iopub.status.idle":"2021-10-28T15:44:25.374327Z","shell.execute_reply.started":"2021-10-28T15:44:25.362995Z","shell.execute_reply":"2021-10-28T15:44:25.373238Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Combining both datasets\n# so that we can analyse the complete dataset\nnews = pd.concat([real_news, fake_news], ignore_index=True)\nnews.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.376440Z","iopub.execute_input":"2021-10-28T15:44:25.376784Z","iopub.status.idle":"2021-10-28T15:44:25.400910Z","shell.execute_reply.started":"2021-10-28T15:44:25.376737Z","shell.execute_reply":"2021-10-28T15:44:25.399784Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Step 4 : Scrubbing Data","metadata":{}},{"cell_type":"code","source":"# Checking for missing values\nnews.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.402828Z","iopub.execute_input":"2021-10-28T15:44:25.403180Z","iopub.status.idle":"2021-10-28T15:44:25.438840Z","shell.execute_reply.started":"2021-10-28T15:44:25.403136Z","shell.execute_reply":"2021-10-28T15:44:25.437908Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**As you can see there is no missing values, so our data is clean**","metadata":{}},{"cell_type":"code","source":"# As we are running the analysis with the news titles \n# hence the remaining columns are not required.\nnews = news.drop(['text', 'subject', 'date'], axis=1)\nnews.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.440598Z","iopub.execute_input":"2021-10-28T15:44:25.441912Z","iopub.status.idle":"2021-10-28T15:44:25.460565Z","shell.execute_reply.started":"2021-10-28T15:44:25.441848Z","shell.execute_reply":"2021-10-28T15:44:25.459182Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Step 5 : Exploring Data Analysis","metadata":{}},{"cell_type":"code","source":"# Displaying the size of datasets\nprint(f\"Real news size : {real_news.shape}\")\nprint(f\"Fake news size : {fake_news.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.463427Z","iopub.execute_input":"2021-10-28T15:44:25.463871Z","iopub.status.idle":"2021-10-28T15:44:25.470719Z","shell.execute_reply.started":"2021-10-28T15:44:25.463835Z","shell.execute_reply":"2021-10-28T15:44:25.469748Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Real/Fake news distribution\nfake_news_count, real_news_count = news.isReal.value_counts()\nprint(f\"Fake news count : {fake_news_count}\")\nprint(f\"Real news count : {real_news_count}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.472267Z","iopub.execute_input":"2021-10-28T15:44:25.472527Z","iopub.status.idle":"2021-10-28T15:44:25.486470Z","shell.execute_reply.started":"2021-10-28T15:44:25.472498Z","shell.execute_reply":"2021-10-28T15:44:25.485365Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data = news, x = \"isReal\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.488557Z","iopub.execute_input":"2021-10-28T15:44:25.489198Z","iopub.status.idle":"2021-10-28T15:44:25.656948Z","shell.execute_reply.started":"2021-10-28T15:44:25.489153Z","shell.execute_reply":"2021-10-28T15:44:25.655814Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**The labels seems to be evenly distributed. This is a good sign and confirms that the dataset is not biased.**","metadata":{}},{"cell_type":"markdown","source":"## Step 6 : Natural Language Processing","metadata":{}},{"cell_type":"markdown","source":"### 1 - Processing text","metadata":{}},{"cell_type":"code","source":"wordnet = WordNetLemmatizer()\ncorpus = []\n\ntitles = news['title'].values\nfor title in titles:\n    # Cleaning text\n    review = re.sub('[^a-zA-Z]', ' ', title)\n    \n    # Formating text\n    review = review.lower()\n    review = review.split()\n    \n    # Lemmatize each word in text\n    review = [wordnet.lemmatize(word) \n              for word in review\n              if word not in stopwords.words('english')]\n    \n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:44:25.659234Z","iopub.execute_input":"2021-10-28T15:44:25.659943Z","iopub.status.idle":"2021-10-28T15:45:48.129636Z","shell.execute_reply.started":"2021-10-28T15:44:25.659889Z","shell.execute_reply":"2021-10-28T15:45:48.128801Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**First title Before processing :**","metadata":{}},{"cell_type":"code","source":"print(news.loc[0, 'title'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-28T15:45:48.132352Z","iopub.execute_input":"2021-10-28T15:45:48.132570Z","iopub.status.idle":"2021-10-28T15:45:48.138748Z","shell.execute_reply.started":"2021-10-28T15:45:48.132543Z","shell.execute_reply":"2021-10-28T15:45:48.137794Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**First title After processing :**","metadata":{}},{"cell_type":"code","source":"print(corpus[0])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-28T15:45:48.139832Z","iopub.execute_input":"2021-10-28T15:45:48.140034Z","iopub.status.idle":"2021-10-28T15:45:48.150105Z","shell.execute_reply.started":"2021-10-28T15:45:48.140008Z","shell.execute_reply":"2021-10-28T15:45:48.149539Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### 2 - Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Bag of Words using countVectorizer\ncv = CountVectorizer()\nX_bw = cv.fit_transform(corpus).toarray()\nX_bw.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:48.150987Z","iopub.execute_input":"2021-10-28T15:45:48.151516Z","iopub.status.idle":"2021-10-28T15:45:49.745792Z","shell.execute_reply.started":"2021-10-28T15:45:48.151482Z","shell.execute_reply":"2021-10-28T15:45:49.744827Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# TF_IDF\ntfidf_v = TfidfVectorizer()\nX_tfidf = tfidf_v.fit_transform(corpus).toarray()\nX_tfidf.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:49.747196Z","iopub.execute_input":"2021-10-28T15:45:49.747523Z","iopub.status.idle":"2021-10-28T15:45:52.296472Z","shell.execute_reply.started":"2021-10-28T15:45:49.747467Z","shell.execute_reply":"2021-10-28T15:45:52.295607Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"count_df = pd.DataFrame(X_bw, columns=cv.get_feature_names())\ncount_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-28T15:45:52.297616Z","iopub.execute_input":"2021-10-28T15:45:52.297846Z","iopub.status.idle":"2021-10-28T15:45:52.331937Z","shell.execute_reply.started":"2021-10-28T15:45:52.297820Z","shell.execute_reply":"2021-10-28T15:45:52.330997Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"count_df = pd.DataFrame(X_tfidf, columns=tfidf_v.get_feature_names())\ncount_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:52.333053Z","iopub.execute_input":"2021-10-28T15:45:52.333271Z","iopub.status.idle":"2021-10-28T15:45:52.382372Z","shell.execute_reply.started":"2021-10-28T15:45:52.333244Z","shell.execute_reply":"2021-10-28T15:45:52.381759Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Step 8 : Models Training","metadata":{}},{"cell_type":"code","source":"# Target feature\ny = news[\"isReal\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:52.383504Z","iopub.execute_input":"2021-10-28T15:45:52.384195Z","iopub.status.idle":"2021-10-28T15:45:52.387933Z","shell.execute_reply.started":"2021-10-28T15:45:52.384159Z","shell.execute_reply":"2021-10-28T15:45:52.387150Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### 1 - Bag of Words","metadata":{}},{"cell_type":"code","source":"# Divide the dataset into Train and Test\nX_train, X_test, y_train, y_test = train_test_split(\n    X_bw, y, test_size=0.33, random_state=0)\n\nclassifier = MultinomialNB()         # Choose model hyperparameters\nclassifier.fit(X_train, y_train)     # Fit model to data\nbw_pred = classifier.predict(X_test) # Predict on new data ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:52.389229Z","iopub.execute_input":"2021-10-28T15:45:52.389450Z","iopub.status.idle":"2021-10-28T15:46:03.396026Z","shell.execute_reply.started":"2021-10-28T15:45:52.389422Z","shell.execute_reply":"2021-10-28T15:46:03.394994Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### 2 - TF-IDF","metadata":{}},{"cell_type":"code","source":"# Divide the dataset into Train and Test\nX_train, X_test, y_train, y_test = train_test_split(\n    X_tfidf, y, test_size=0.33, random_state=0)\n\nclassifier = MultinomialNB()            # Choose model hyperparameters\nclassifier.fit(X_train, y_train)        # Fit model to data\ntfidf_pred = classifier.predict(X_test) # Predict on new data ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:03.397807Z","iopub.execute_input":"2021-10-28T15:46:03.398363Z","iopub.status.idle":"2021-10-28T15:46:08.404087Z","shell.execute_reply.started":"2021-10-28T15:46:03.398304Z","shell.execute_reply":"2021-10-28T15:46:08.403085Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Step 9 : Models Evaluation","metadata":{}},{"cell_type":"markdown","source":"### 1 - Bag of Words","metadata":{}},{"cell_type":"code","source":"bw_score = accuracy_score(y_test, bw_pred)\ncm = confusion_matrix(y_test, bw_pred)\nprint(f\"Accuracy: {round(bw_score, 2)}\")\nprint(f\"Confusion matrix:\\n {cm}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:08.405825Z","iopub.execute_input":"2021-10-28T15:46:08.406380Z","iopub.status.idle":"2021-10-28T15:46:08.456776Z","shell.execute_reply.started":"2021-10-28T15:46:08.406326Z","shell.execute_reply":"2021-10-28T15:46:08.455872Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"*With Bag of Words we achieved maximum accuracy of 94%*","metadata":{}},{"cell_type":"markdown","source":"### 2 - TF-IDF","metadata":{}},{"cell_type":"code","source":"tfidf_score = accuracy_score(y_test, tfidf_pred)\ncm = confusion_matrix(y_test, tfidf_pred)\nprint(f\"Accuracy: {round(tfidf_score, 2)}\")\nprint(f\"Confusion matrix:\\n {cm}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:08.458790Z","iopub.execute_input":"2021-10-28T15:46:08.459519Z","iopub.status.idle":"2021-10-28T15:46:08.509776Z","shell.execute_reply.started":"2021-10-28T15:46:08.459461Z","shell.execute_reply":"2021-10-28T15:46:08.508875Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"*With TF-IDF we are able to achieve an accuracy on 93%*","metadata":{}},{"cell_type":"markdown","source":"## Step 10 : Summary\nWe analyzed the accuracy, For TF-IDF we achieved the accuracy of 93% and for Bag of Words it is 94%, so we conclude that Bag of Words have performed better than Bag TF-IDF","metadata":{}},{"cell_type":"code","source":"models = ['Bag of Words', 'TF-IDF']\nscore = [bw_score, tfidf_score]\nsns.barplot(x=models, y=score)\nplt.title('Models Performance', fontsize=15)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Performance', fontsize=15)\nplt.ylim(0, 1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:08.511706Z","iopub.execute_input":"2021-10-28T15:46:08.512397Z","iopub.status.idle":"2021-10-28T15:46:08.692368Z","shell.execute_reply.started":"2021-10-28T15:46:08.512344Z","shell.execute_reply":"2021-10-28T15:46:08.691733Z"},"trusted":true},"execution_count":25,"outputs":[]}]}